{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "btSzm_v7bojO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQCneCAtbg_V"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import os\n",
        "import IPython\n",
        "import time\n",
        "import re\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "SF7S2Iubbw9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini configuration"
      ],
      "metadata": {
        "id": "ZjEtt-AJMIbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API key\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key = GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "1bhRQt-_cM9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_instruction = \"You are a sustainability expert consultant. You must respond with facts.\""
      ],
      "metadata": {
        "id": "w3GFuZq7McI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash-002',system_instruction=system_instruction) # gemini-1.5-flash # gemini-1.5-pro # gemini-pro # gemini-1.5-flash-002"
      ],
      "metadata": {
        "id": "5lruH1UCMWsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adjust model's temperature, top_p, top_k (0 for more deterministic answers)"
      ],
      "metadata": {
        "id": "2Rryifqtevld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = genai.GenerationConfig(top_p = 0, temperature = 0, top_k= 1)"
      ],
      "metadata": {
        "id": "YXuIFbUgeule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safety settings"
      ],
      "metadata": {
        "id": "9J-LR2cjfNDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\",\n",
        "    },\n",
        "]"
      ],
      "metadata": {
        "id": "sB5Kddr3fO-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount drive"
      ],
      "metadata": {
        "id": "Rm0p6U0efiC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Base path\n",
        "base_path = \"/content/drive/My Drive\"\n",
        "\n",
        "# Define the folder path in your Google Drive\n",
        "general_path = os.path.join(base_path,\"TrabajoWater\")\n",
        "\n",
        "# Check if the folder exists, if not, create it\n",
        "if not os.path.exists(general_path):\n",
        "    os.makedirs(general_path)\n",
        "    print(f\"Created path {general_path}\")"
      ],
      "metadata": {
        "id": "D5oH-OO9MnyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Response folder"
      ],
      "metadata": {
        "id": "A8pWBU0_CVKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The SDGs predicted in the previous part\n",
        "sdg_predictions = os.path.join(general_path,\"Raw_Results_Flash_002\",\"Prompt_SDG_Allocation_Water_SDG1\")"
      ],
      "metadata": {
        "id": "oaoPDDPUCWlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The folder where the new responses will be saved.\n",
        "interaction_water_folder = os.path.join(general_path,\"Raw_Results_Flash_002\",\"Prompt_SDG_InteractionWithWater_SDG1\")\n",
        "if not os.path.exists(interaction_water_folder):\n",
        "    os.makedirs(interaction_water_folder)\n",
        "    print(f\"Created path {interaction_water_folder}\")"
      ],
      "metadata": {
        "id": "71zd1Wk9ERoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excel with all texts"
      ],
      "metadata": {
        "id": "2z_q8ISLhRPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_excel = os.path.join(general_path,\"Excels_Original_Cientificos/Water_SDG1.xlsx\") # The Excel that is\n",
        "print(path_excel)"
      ],
      "metadata": {
        "id": "7pYhAzh1MpYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(path_excel)\n",
        "df.columns = df.iloc[0]  # Assign the first row as the header\n",
        "df = df[1:].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GrTLcASHMpvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "odr_d2cGMqvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "8bY9q8ERCUZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_sdgs_and_reasons(file_path):\n",
        "    sdgs = []\n",
        "    reasons = []\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"UTF-8\") as file:\n",
        "      content = file.read()\n",
        "\n",
        "    # Preprocess the content to remove unwanted characters like *, **, and -\n",
        "    content = content.replace(\"*\", \"\").replace(\"**\", \"\")\n",
        "\n",
        "    # Updated SDG pattern to handle SDG names with commas, multiple spaces, or special characters\n",
        "    sdg_pattern = r'SDG\\s*(\\d+)\\s*([^\\n]+?)\\s*Reason:'\n",
        "    reason_pattern = r'Reason:\\s*([^\\n]+)'\n",
        "\n",
        "    # Find all SDG matches\n",
        "    sdg_matches = re.findall(sdg_pattern, content)\n",
        "\n",
        "    # Find all Reason matches\n",
        "    reason_matches = re.findall(reason_pattern, content)\n",
        "\n",
        "    # Pair SDGs and Reasons\n",
        "    for i, (sdg_num, sdg_name) in enumerate(sdg_matches):\n",
        "        sdgs.append(f\"SDG{sdg_num} {sdg_name.strip()}\")\n",
        "\n",
        "        # Ensure we have a corresponding reason\n",
        "        if i < len(reason_matches):\n",
        "            reasons.append(reason_matches[i].strip())\n",
        "\n",
        "    if len(sdgs) != len(reasons):\n",
        "        print(f\"Mismatch in SDGs andr easons for file {file_path}.\")\n",
        "        print(content)\n",
        "\n",
        "    if len(sdgs) == 0:\n",
        "        print(f\"No SDG found for file {file_path}\")\n",
        "        print(content)\n",
        "\n",
        "    return sdgs, reasons\n"
      ],
      "metadata": {
        "id": "7tANpJ64GOUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_sdg(sdg):\n",
        "    sdg = str(sdg).strip().lower()  # Convert to lowercase and remove any extra spaces\n",
        "\n",
        "    if any(keyword in sdg for keyword in ['no poverty', 'poverty', 'poor']):\n",
        "        return '1) No Poverty'\n",
        "    elif any(keyword in sdg for keyword in ['zero hunger', 'hunger']):\n",
        "        return '2) Zero Hunger'\n",
        "    elif any(keyword in sdg for keyword in ['good health and well-being', 'healthy', 'health', 'aids']):\n",
        "        return '3) Good Health and Well-being'\n",
        "    elif 'quality education' in sdg:\n",
        "        return '4) Quality Education'\n",
        "    elif any(keyword in sdg for keyword in ['gender equality', 'women']):\n",
        "        return '5) Gender Equality'\n",
        "    elif any(keyword in sdg for keyword in ['clean water and sanitation', 'chemicals', 'water and sanitation']):\n",
        "        return '6) Clean Water and Sanitation'\n",
        "    elif any(keyword in sdg for keyword in ['affordable and clean energy', 'energy']):\n",
        "        return '7) Affordable and Clean Energy'\n",
        "    elif any(keyword in sdg for keyword in ['decent work and economic growth', 'economic growth']):\n",
        "        return '8) Decent Work and Economic Growth'\n",
        "    elif any(keyword in sdg for keyword in ['industry', 'innovation', 'infrastructure']):\n",
        "        return '9) Industry, Innovation and Infrastructure'\n",
        "    elif 'reduced inequalities' in sdg or 'inequality' in sdg or 'reduce inequalities' in sdg:\n",
        "        return '10) Reduced Inequalities'\n",
        "    elif any(keyword in sdg for keyword in ['sustainable cities', 'cities']):\n",
        "        return '11) Sustainable Cities and Communities'\n",
        "    elif any(keyword in sdg for keyword in ['responsible consumption', 'consumption']):\n",
        "        return '12) Responsible Consumption and Production'\n",
        "    elif any(keyword in sdg for keyword in ['climate action', 'climate change']):\n",
        "        return '13) Climate Action'\n",
        "    elif any(keyword in sdg for keyword in ['life below water', 'oceans', 'life under water']):\n",
        "        return '14) Life Below Water'\n",
        "    elif any(keyword in sdg for keyword in ['life on land', 'forest', 'land and soil']):\n",
        "        return '15) Life on Land'\n",
        "    elif any(keyword in sdg for keyword in ['peace', 'justice', 'strong institutions','rule of law']):\n",
        "        return '16) Peace, Justice and Strong Institutions'\n",
        "    elif any(keyword in sdg for keyword in ['partnerships', 'partnership','sustainable development goals']):\n",
        "        return '17) Partnerships for the Goals'\n",
        "    elif any(keyword in sdg for keyword in ['no sdg', 'nan', 'n/a', 'not applicable']):\n",
        "        return \"No SDG\"\n",
        "    elif any(keyword in Link for keyword in ['Synergy']):\n",
        "        return 'Synergy'\n",
        "    elif any(keyword in sdg for keyword in ['Trade-off']):\n",
        "        return 'Trade-off'\n",
        "    else:\n",
        "        return sdg\n"
      ],
      "metadata": {
        "id": "FXWC9DqtGSoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loop through Excel"
      ],
      "metadata": {
        "id": "WJusGyW_jP7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of samples\n",
        "start_index = 0\n",
        "\n",
        "# Define the starting index for the second batch\n",
        "end_index = 4875\n",
        "\n",
        "# Loop through the indexes of the DataFrame from 0 to 20\n",
        "for index in range(start_index, end_index):\n",
        "    # Cada texto del excel\n",
        "    print(\"%\")\n",
        "    print(index)\n",
        "    paragraph = df.loc[index, 'FullText']\n",
        "\n",
        "    # Old answers\n",
        "    sdg_prediction_path = os.path.join(sdg_predictions, f\"{index}.txt\")\n",
        "\n",
        "    if not os.path.exists(sdg_prediction_path):\n",
        "        print(f\"Skipping {sdg_prediction_path}...\")\n",
        "        continue\n",
        "\n",
        "    sdgs, reasons = extract_sdgs_and_reasons(sdg_prediction_path)\n",
        "    relevant_sdgs = []\n",
        "    for sdg in sdgs:\n",
        "            mapped_sdg = map_sdg(sdg)\n",
        "            if mapped_sdg != 'Wrong' and mapped_sdg != 'No SDG' and mapped_sdg != '6) Clean Water and Sanitation':\n",
        "                relevant_sdgs.append(mapped_sdg)\n",
        "\n",
        "    if len(relevant_sdgs) <= 0:\n",
        "      print(f\"Skipping file {sdg_prediction_path}, no relevant sdgs...\")\n",
        "      continue\n",
        "\n",
        "    # Where to save the new answer\n",
        "    destination_path = os.path.join(interaction_water_folder, f\"{index}.txt\")\n",
        "    if os.path.exists(destination_path):\n",
        "        print(f\"Skipping {destination_path} because it already exists...\")\n",
        "        continue\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are provided with the content of a scientific article about Water. Your task is to analyze the relationship between each predicted SDG with SDG 6) Clean Water and Sanitation. Exclude any references, acknowledgments, titles, and authors in your decision-making, and focus exclusively on the article’s main content.\n",
        "\n",
        "    **Instructions**\n",
        "\n",
        "    You must identify whether the link would result in a synergy, a trade-off, or it is a neutral link:\n",
        "\n",
        "      - Synergy: achieving the SDG through the measures discussed in the article would benefit SDG 6) Clean Water and Sanitation\n",
        "      - Trade-off: achieving the SDG through the measures discussed in the article would put pressure or harm SDG 6) Clean Water and Sanitation\n",
        "      - Neutral: achieving the SDG through the measures discussed in the article would not have a significant effect or the link is not clear between the SDG and SDG 6) Clean Water and Sanitation\n",
        "\n",
        "     Write an exact sentence from the article that led you to decide whether there is synergy, trade-off or neutral.\n",
        "\n",
        "    **Original article**\n",
        "\n",
        "    Article: \"{paragraph}\"\n",
        "\n",
        "    **Output Format:**\n",
        "    \"\"\"\n",
        "\n",
        "    for sdg in relevant_sdgs:\n",
        "      if sdg != \"6) Clean Water and Sanitation\":\n",
        "        prompt += f\"\"\"\n",
        "              - SDG Pair: SDG {sdg} - SDG 6) Clean Water and Sanitation\n",
        "                - Relationship: [Synergy/Trade-off/Neutral]\n",
        "                - Explanation: [Reason how each measure impacts SDG 6) Clean Water and Sanitation with references from the text and reasoning the possible outcomes according to the achievement of SDG {sdg} in the context of the article]\n",
        "        \"\"\"\n",
        "\n",
        "    print(prompt)\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(prompt, safety_settings=safety_settings, generation_config=generation_config)\n",
        "        print(response.text)\n",
        "\n",
        "        with open(destination_path, 'w') as file:  # Asegúrate de abrir el archivo aquí\n",
        "          file.write(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        if '500' in str(e):\n",
        "            print(\"=========================================== Exception 500 =========================================== \")\n",
        "        elif '429' in str(e):  # si sale más de 20 veces seguidas, cambiar de clave o esperar al día siguiente\n",
        "            print(\"=========================================== Exception 429 =========================================== \")\n",
        "            time.sleep(5)\n",
        "        elif 'Read timed out' in str(e):  # Reiniciar sesión y ejecutar todo\n",
        "            print(\"=========================================== Exception 600 =========================================== \")\n",
        "        else:\n",
        "            print(f\"Skipping due to error: {e}\")\n"
      ],
      "metadata": {
        "id": "6CGfehZTM16p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract responses"
      ],
      "metadata": {
        "id": "5b-jBKM_M8s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files = glob.glob(os.path.join(interaction_water_folder, '*.txt'))\n",
        "\n",
        "csv = df.copy()\n",
        "\n",
        "# Define a function to extract numerical part from the filename\n",
        "def extract_number(filename):\n",
        "    match = re.search(r'(\\d+)', filename)\n",
        "    return int(match.group()) if match else float('inf')\n",
        "\n",
        "# Sort files based on the numerical part\n",
        "sorted_files = sorted(txt_files, key=lambda f: extract_number(os.path.basename(f)))\n",
        "print(sorted_files)"
      ],
      "metadata": {
        "id": "0EWmYmEUM2ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_info_from_file(file_path):\n",
        "\n",
        "    results = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        text = file.read()\n",
        "\n",
        "    text = text.replace(\"**\",\"\")\n",
        "\n",
        "    # ************************************************************************ #\n",
        "\n",
        "    pattern = re.compile(\n",
        "    r\"SDG Pair:\\s+SDG\\s*(\\d+)\\s*\\)\\s*(.*?)\\s*-\\s*SDG\\s*(\\d+)\\s*\\)\\s*(.*?)\\n\"\n",
        "    r\"\\s*- Relationship:\\s*(.*?)\\n\"\n",
        "    r\"\\s*- Explanation:\\s*(.*?)(?=\\n\\s*- SDG Pair|\\Z)\",\n",
        "    re.DOTALL\n",
        "    )\n",
        "\n",
        "    # Find all matches in the text\n",
        "    matches = pattern.findall(text)\n",
        "\n",
        "    # Check if any matches were found\n",
        "    if not matches:\n",
        "        print(f\"No matches found\\n{text}\")\n",
        "        return results\n",
        "\n",
        "    # Iterate through the matches and build the result list\n",
        "    for match in matches:\n",
        "        sdg_a = f\"SDG{match[0]} {match[1].strip()}\"\n",
        "        if match[2]:  # If second SDG is captured\n",
        "            sdg_b = f\"SDG{match[2]} {match[3].strip()}\"\n",
        "        else:  # If no second SDG is present\n",
        "            sdg_b = f\"SDG{match[0]} {match[1].strip()}\"  # Duplicate SDG with empty text for consistency\n",
        "\n",
        "\n",
        "        relationship = match[4].strip()\n",
        "\n",
        "        explanation = match[5].strip()\n",
        "\n",
        "        results.append((sdg_a, sdg_b, relationship, explanation))\n",
        "\n",
        "\n",
        "\n",
        "    # ************************************************************************ #\n",
        "\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "jkknwctLM-Wf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_files_and_update_dataframe(sorted_files, original_df, response_directory_ST):\n",
        "\n",
        "    new_rows = []\n",
        "    current_index = 0  # Keep track of the expected index\n",
        "    suma = 0\n",
        "\n",
        "    for file in sorted_files:\n",
        "        # Extract index from filename\n",
        "        index = extract_number(os.path.basename(file))  # Assuming you have a function to extract the number\n",
        "        print(\"/\" * 50)\n",
        "        print(index)\n",
        "\n",
        "        file_path = os.path.join(response_directory_ST, f'{index}.txt')\n",
        "        if not os.path.exists(file_path):\n",
        "            # Create a new row with the original row's data\n",
        "            row = original_df.loc[index].copy()\n",
        "            new_rows.append(row)\n",
        "            continue\n",
        "\n",
        "        # Extract SDG-related information from the file\n",
        "        all_pairs_info = extract_info_from_file(file_path)\n",
        "\n",
        "        # Iterate through extracted pairs\n",
        "        if all_pairs_info:\n",
        "          for sdg_a, sdg_b, relationship, explanation in all_pairs_info:\n",
        "              # Add a new row with SDG information\n",
        "              row = original_df.loc[index].copy()  # Get the existing row for the current index\n",
        "              row['SDG A'] = sdg_a\n",
        "              row['SDG B'] = sdg_b\n",
        "              row['Link'] = relationship\n",
        "              row['Explanation'] = explanation\n",
        "              new_rows.append(row)\n",
        "              current_index += 1\n",
        "        else:\n",
        "            # Create a new row with the original row's data\n",
        "            print(\"No prints found...\")\n",
        "            print(\"*\" * 50)\n",
        "            print(f\"Index: {index}\")\n",
        "            row = original_df.loc[index].copy()\n",
        "            new_rows.append(row)\n",
        "            suma += 1\n",
        "\n",
        "    # Create a new dataframe from the rows collected\n",
        "    updated_df = pd.DataFrame(new_rows)\n",
        "\n",
        "    # Return the new dataframe with SDG information\n",
        "    print(f\"There are {suma} wrong files\")\n",
        "    return updated_df"
      ],
      "metadata": {
        "id": "M1nl6OPIM_fD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated = process_files_and_update_dataframe(sorted_files, csv, interaction_water_folder)"
      ],
      "metadata": {
        "id": "1TGIsxwqNAoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated.head()"
      ],
      "metadata": {
        "id": "KhL7BnnjNDQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated.to_excel(os.path.join(general_path,\"SDG1_interaction.xlsx\"))"
      ],
      "metadata": {
        "id": "YM0eMpOJNEcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files = glob.glob(os.path.join(sdg_predictions, '*.txt'))\n",
        "\n",
        "# Sort files based on the numerical part\n",
        "sorted_files_2 = sorted(txt_files, key=lambda f: extract_number(os.path.basename(f)))\n",
        "print(sorted_files_2)"
      ],
      "metadata": {
        "id": "6CTAcQhxNPm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the main CSV file\n",
        "main_csv = df_updated.copy()\n",
        "\n",
        "# Initialize a list to store the final data with columns from the main CSV file\n",
        "final_data = []\n",
        "\n",
        "# Initialize a list of available indices based on the files we have\n",
        "available_indices = [extract_number(os.path.basename(file)) for file in sorted_files_2]\n",
        "\n",
        "# Process each file in sorted order\n",
        "for file in sorted_files_2:\n",
        "    # Extract the index or identifier for this file\n",
        "    file_index = extract_number(os.path.basename(file))\n",
        "    sdgs, reasons = extract_sdgs_and_reasons(file)  # Extract SDGs and reasons\n",
        "\n",
        "    # Extract relevant SDGs based on mapping\n",
        "    relevant_sdgs = []\n",
        "    for sdg in sdgs:\n",
        "        mapped_sdg = map_sdg(sdg)\n",
        "        if mapped_sdg != 'Wrong' and mapped_sdg != 'No SDG' and mapped_sdg != '6) Clean Water and Sanitation':\n",
        "            relevant_sdgs.append(mapped_sdg)\n",
        "\n",
        "    # Find the row in main_csv that corresponds to this file's index\n",
        "    if file_index < len(main_csv):\n",
        "        original_row = main_csv.iloc[file_index].to_dict()\n",
        "    else:\n",
        "        # If index not found, skip to next file\n",
        "        continue\n",
        "\n",
        "    # Add the original paragraph number\n",
        "    original_row['Paragraph number'] = file_index\n",
        "\n",
        "    # Case 1: If only one or no relevant SDG is allocated\n",
        "    #if len(relevant_sdgs) <= 1:\n",
        "    #    final_data.append({**original_row, 'SDG A': 'Only 1 SDG Allocated', 'SDG B': 'Only 1 SDG Allocated'})\n",
        "    #    continue\n",
        "\n",
        "    # Case 2: Generate all combinations of SDG pairs for this index and add to the data\n",
        "    for sdg in relevant_sdgs:\n",
        "        final_data.append({**original_row, 'SDG A': sdg, 'SDG B': '6) Clean Water and Sanitation'})\n",
        "\n",
        "# Process the indices in main_csv that are not available in sorted_files\n",
        "for idx, row in main_csv.iterrows():\n",
        "    if idx not in available_indices:\n",
        "        row_data = row.to_dict()\n",
        "        row_data.update({\n",
        "            'SDG A': 'Blocked SDG Allocation',\n",
        "            'SDG B': 'Blocked SDG Allocation',\n",
        "            'Paragraph number': idx\n",
        "        })\n",
        "        final_data.append(row_data)\n",
        "\n",
        "# Convert the final data list to a DataFrame\n",
        "df_sdg_pairs = pd.DataFrame(final_data)\n",
        "\n",
        "df_sdg_pairs.insert(0, 'Paragraph number', df_sdg_pairs.pop('Paragraph number'))"
      ],
      "metadata": {
        "id": "1lEbF-5BNQM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sdg_pairs.head()"
      ],
      "metadata": {
        "id": "tAHm1FFXNSck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sdg_number(sdg_full_name):\n",
        "    sdg_map = {\n",
        "        '1) No Poverty': '1',\n",
        "        '2) Zero Hunger': '2',\n",
        "        '3) Good Health and Well-being': '3',\n",
        "        '4) Quality Education': '4',\n",
        "        '5) Gender Equality': '5',\n",
        "        '6) Clean Water and Sanitation': '6',\n",
        "        '7) Affordable and Clean Energy': '7',\n",
        "        '8) Decent Work and Economic Growth': '8',\n",
        "        '9) Industry, Innovation and Infrastructure': '9',\n",
        "        '10) Reduced Inequalities': '10',\n",
        "        '11) Sustainable Cities and Communities': '11',\n",
        "        '12) Responsible Consumption and Production': '12',\n",
        "        '13) Climate Action': '13',\n",
        "        '14) Life Below Water': '14',\n",
        "        '15) Life on Land': '15',\n",
        "        '16) Peace, Justice and Strong Institutions': '16',\n",
        "        '17) Partnerships for the Goals': '17',\n",
        "        'No SDG': 'No SDG'\n",
        "    }\n",
        "\n",
        "    return sdg_map.get(sdg_full_name, sdg_full_name)"
      ],
      "metadata": {
        "id": "-ue8pZM-NSva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the mapping function to both columns\n",
        "df_sdg_pairs['SDG A c'] = df_sdg_pairs['SDG A'].apply(get_sdg_number)\n",
        "df_sdg_pairs['SDG B c'] = df_sdg_pairs['SDG B'].apply(get_sdg_number)"
      ],
      "metadata": {
        "id": "q2lN_B4aNUcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the unique values of 'Link' along with their counts\n",
        "link_counts = df_sdg_pairs['Link'].value_counts()\n",
        "\n",
        "print(link_counts)"
      ],
      "metadata": {
        "id": "oIAHcsf-NVrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Count occurrences of each pair using groupby\n",
        "pair_counts = df_sdg_pairs.groupby(['SDG A c', 'SDG B c']).size().reset_index(name='count')\n",
        "\n",
        "# Step 4: Create a pivot table\n",
        "pivot_table = pair_counts.pivot(index='SDG A c', columns='SDG B c', values='count').fillna(0)\n",
        "\n",
        "# Step 5: Sort the index and columns numerically\n",
        "pivot_table.index = pd.to_numeric(pivot_table.index, errors='coerce')\n",
        "pivot_table.columns = pd.to_numeric(pivot_table.columns, errors='coerce')\n",
        "pivot_table = pivot_table.sort_index().sort_index(axis=1)\n",
        "\n",
        "# Step 6: Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "heatmap = sns.heatmap(pivot_table, annot=True, cmap='Reds', fmt=\".0f\", linewidths=.5, cbar_kws={\"orientation\": \"vertical\"},cbar=False)\n",
        "\n",
        "# Adjust tick positions to be centered\n",
        "plt.xticks(ticks=np.arange(len(pivot_table.columns)) + 0.5, labels=pivot_table.columns.astype(str), rotation=0)\n",
        "plt.yticks(ticks=np.arange(len(pivot_table.index)) + 0.5, labels=pivot_table.index.astype(str), rotation=0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('All connections - Gemini - Standard')\n",
        "plt.xlabel('Connected SDG')\n",
        "plt.ylabel('Base SDG')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5FZJm5kVNWqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter the DataFrame where 'Link' is 'Synergy'\n",
        "df_out = df_sdg_pairs[df_sdg_pairs['Link'] == 'Synergy']\n",
        "\n",
        "# Step 3: Count occurrences of each pair using groupby\n",
        "pair_counts = df_out.groupby(['SDG A c', 'SDG B c']).size().reset_index(name='count')\n",
        "\n",
        "# Step 4: Create a pivot table\n",
        "pivot_table = pair_counts.pivot(index='SDG A c', columns='SDG B c', values='count').fillna(0)\n",
        "\n",
        "# Step 5: Sort the index and columns numerically\n",
        "pivot_table.index = pd.to_numeric(pivot_table.index, errors='coerce')\n",
        "pivot_table.columns = pd.to_numeric(pivot_table.columns, errors='coerce')\n",
        "pivot_table = pivot_table.sort_index().sort_index(axis=1)\n",
        "\n",
        "# Step 6: Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "heatmap = sns.heatmap(pivot_table, annot=True, cmap='Reds', fmt=\".0f\", linewidths=.5, cbar_kws={\"orientation\": \"vertical\"},cbar=False)\n",
        "\n",
        "# Adjust tick positions to be centered\n",
        "plt.xticks(ticks=np.arange(len(pivot_table.columns)) + 0.5, labels=pivot_table.columns.astype(str), rotation=0)\n",
        "plt.yticks(ticks=np.arange(len(pivot_table.index)) + 0.5, labels=pivot_table.index.astype(str), rotation=0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Synergy connections - Gemini ')\n",
        "plt.xlabel('Connected SDG')\n",
        "plt.ylabel('Base SDG')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r1uQb-KqNZcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter the DataFrame where 'Link' is 'Synergy'\n",
        "df_out = df_sdg_pairs[df_sdg_pairs['Link'] == 'Trade-off']\n",
        "\n",
        "# Step 3: Count occurrences of each pair using groupby\n",
        "pair_counts = df_out.groupby(['SDG A c', 'SDG B c']).size().reset_index(name='count')\n",
        "\n",
        "# Step 4: Create a pivot table\n",
        "pivot_table = pair_counts.pivot(index='SDG A c', columns='SDG B c', values='count').fillna(0)\n",
        "\n",
        "# Step 5: Sort the index and columns numerically\n",
        "pivot_table.index = pd.to_numeric(pivot_table.index, errors='coerce')\n",
        "pivot_table.columns = pd.to_numeric(pivot_table.columns, errors='coerce')\n",
        "pivot_table = pivot_table.sort_index().sort_index(axis=1)\n",
        "\n",
        "# Step 6: Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "heatmap = sns.heatmap(pivot_table, annot=True, cmap='Reds', fmt=\".0f\", linewidths=.5, cbar_kws={\"orientation\": \"vertical\"},cbar=False)\n",
        "\n",
        "# Adjust tick positions to be centered\n",
        "plt.xticks(ticks=np.arange(len(pivot_table.columns)) + 0.5, labels=pivot_table.columns.astype(str), rotation=0)\n",
        "plt.yticks(ticks=np.arange(len(pivot_table.index)) + 0.5, labels=pivot_table.index.astype(str), rotation=0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Trade-off connections - Gemini ')\n",
        "plt.xlabel('Connected SDG')\n",
        "plt.ylabel('Base SDG')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YR5z3M4QNbrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Filter the DataFrame where 'Link' is 'Synergy'\n",
        "df_out = df_sdg_pairs[df_sdg_pairs['Link'] == 'Neutral']\n",
        "\n",
        "# Step 3: Count occurrences of each pair using groupby\n",
        "pair_counts = df_out.groupby(['SDG A c', 'SDG B c']).size().reset_index(name='count')\n",
        "\n",
        "# Step 4: Create a pivot table\n",
        "pivot_table = pair_counts.pivot(index='SDG A c', columns='SDG B c', values='count').fillna(0)\n",
        "\n",
        "# Step 5: Sort the index and columns numerically\n",
        "pivot_table.index = pd.to_numeric(pivot_table.index, errors='coerce')\n",
        "pivot_table.columns = pd.to_numeric(pivot_table.columns, errors='coerce')\n",
        "pivot_table = pivot_table.sort_index().sort_index(axis=1)\n",
        "\n",
        "# Step 6: Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "heatmap = sns.heatmap(pivot_table, annot=True, cmap='Reds', fmt=\".0f\", linewidths=.5, cbar_kws={\"orientation\": \"vertical\"},cbar=False)\n",
        "\n",
        "# Adjust tick positions to be centered\n",
        "plt.xticks(ticks=np.arange(len(pivot_table.columns)) + 0.5, labels=pivot_table.columns.astype(str), rotation=0)\n",
        "plt.yticks(ticks=np.arange(len(pivot_table.index)) + 0.5, labels=pivot_table.index.astype(str), rotation=0)\n",
        "\n",
        "# Title and labels\n",
        "plt.title('Neutral connections - Gemini ')\n",
        "plt.xlabel('Connected SDG')\n",
        "plt.ylabel('Base SDG')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LzNvAcCONc88"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}